{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from nn import NN \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# load data \n",
    "data_path = \"./data/breast_cancer.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data['diagnosis']\n",
    "X = data.drop(['id', 'diagnosis', 'Unnamed: 32'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y to T/F\n",
    "Y = Y.map({'M': True, 'B': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train, test, validation (70, 20, 10) randomly \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "X_test, X_val, Y_test, Y_val = train_test_split(X_test, Y_test, test_size=0.33, random_state=42)\n",
    "\n",
    "# normalize data\n",
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std\n",
    "X_val = (X_val - mean) / std\n",
    "\n",
    "X_train = X_train.values\n",
    "Y_train = Y_train.values\n",
    "X_test = X_test.values\n",
    "Y_test = Y_test.values\n",
    "X_val = X_val.values\n",
    "Y_val = Y_val.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (398, 30)\n",
      "Test data shape:  (114, 30)\n",
      "Validation data shape:  (57, 30)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data shape: \", X_train.shape)\n",
    "print(\"Test data shape: \", X_test.shape)\n",
    "print(\"Validation data shape: \", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension:  30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# neurons: 10 relu -> 5 relu -> 1 sigmoid\n",
    "input_dim = X_train.shape[1]\n",
    "print(\"Input dimension: \", input_dim)\n",
    "output_dim = 1\n",
    "hidden_dims = [10, 5, 1]\n",
    "\n",
    "class model(torch.nn.Module):\n",
    "    def __init__(self): \n",
    "        super(model, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_dim, hidden_dims[0])\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_dims[0], hidden_dims[1])\n",
    "        self.fc3 = torch.nn.Linear(hidden_dims[1], output_dim)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "model = model()\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensor\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32)\n",
    "# change shape to (n, 1)\n",
    "Y_train_tensor = Y_train_tensor.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yinch\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss: 0.6853297352790833\n",
      "Epoch 2, loss: 0.6834248304367065\n",
      "Epoch 3, loss: 0.6815492510795593\n",
      "Epoch 4, loss: 0.6792163848876953\n",
      "Epoch 5, loss: 0.676249086856842\n",
      "Epoch 6, loss: 0.6728821396827698\n",
      "Epoch 7, loss: 0.6693319082260132\n",
      "Epoch 8, loss: 0.6655139923095703\n",
      "Epoch 9, loss: 0.6613584756851196\n",
      "Epoch 10, loss: 0.6569510102272034\n",
      "Epoch 11, loss: 0.6522315740585327\n",
      "Epoch 12, loss: 0.6470612287521362\n",
      "Epoch 13, loss: 0.6413851976394653\n",
      "Epoch 14, loss: 0.635166585445404\n",
      "Epoch 15, loss: 0.628170907497406\n",
      "Epoch 16, loss: 0.6205064654350281\n",
      "Epoch 17, loss: 0.6121031641960144\n",
      "Epoch 18, loss: 0.6028543710708618\n",
      "Epoch 19, loss: 0.592679500579834\n",
      "Epoch 20, loss: 0.5814942717552185\n",
      "Epoch 21, loss: 0.5692687630653381\n",
      "Epoch 22, loss: 0.5559239387512207\n",
      "Epoch 23, loss: 0.5413933992385864\n",
      "Epoch 24, loss: 0.5257412195205688\n",
      "Epoch 25, loss: 0.5090298652648926\n",
      "Epoch 26, loss: 0.4913555681705475\n",
      "Epoch 27, loss: 0.4728664755821228\n",
      "Epoch 28, loss: 0.4535691440105438\n",
      "Epoch 29, loss: 0.4337601661682129\n",
      "Epoch 30, loss: 0.4137301445007324\n",
      "Epoch 31, loss: 0.39371028542518616\n",
      "Epoch 32, loss: 0.37393397092819214\n",
      "Epoch 33, loss: 0.3546048104763031\n",
      "Epoch 34, loss: 0.3359242081642151\n",
      "Epoch 35, loss: 0.31802472472190857\n",
      "Epoch 36, loss: 0.30098894238471985\n",
      "Epoch 37, loss: 0.2848697602748871\n",
      "Epoch 38, loss: 0.26969340443611145\n",
      "Epoch 39, loss: 0.2554721236228943\n",
      "Epoch 40, loss: 0.24219724535942078\n",
      "Epoch 41, loss: 0.22981974482536316\n",
      "Epoch 42, loss: 0.21829040348529816\n",
      "Epoch 43, loss: 0.20757435262203217\n",
      "Epoch 44, loss: 0.19761548936367035\n",
      "Epoch 45, loss: 0.18835656344890594\n",
      "Epoch 46, loss: 0.17979955673217773\n",
      "Epoch 47, loss: 0.1719595044851303\n",
      "Epoch 48, loss: 0.16466061770915985\n",
      "Epoch 49, loss: 0.15788081288337708\n",
      "Epoch 50, loss: 0.1515490710735321\n",
      "Epoch 51, loss: 0.14564673602581024\n",
      "Epoch 52, loss: 0.14015211164951324\n",
      "Epoch 53, loss: 0.1350095123052597\n",
      "Epoch 54, loss: 0.13017398118972778\n",
      "Epoch 55, loss: 0.1256299465894699\n",
      "Epoch 56, loss: 0.1213710755109787\n",
      "Epoch 57, loss: 0.11737818270921707\n",
      "Epoch 58, loss: 0.11361383646726608\n",
      "Epoch 59, loss: 0.11009778827428818\n",
      "Epoch 60, loss: 0.10678239911794662\n",
      "Epoch 61, loss: 0.10361898690462112\n",
      "Epoch 62, loss: 0.10062526166439056\n",
      "Epoch 63, loss: 0.09778828173875809\n",
      "Epoch 64, loss: 0.09509021043777466\n",
      "Epoch 65, loss: 0.0925258919596672\n",
      "Epoch 66, loss: 0.09007862955331802\n",
      "Epoch 67, loss: 0.08775030076503754\n",
      "Epoch 68, loss: 0.08553129434585571\n",
      "Epoch 69, loss: 0.08341025561094284\n",
      "Epoch 70, loss: 0.08136332035064697\n",
      "Epoch 71, loss: 0.0794079527258873\n",
      "Epoch 72, loss: 0.07755248993635178\n",
      "Epoch 73, loss: 0.07579449564218521\n",
      "Epoch 74, loss: 0.07411164790391922\n",
      "Epoch 75, loss: 0.07249987125396729\n",
      "Epoch 76, loss: 0.07095431536436081\n",
      "Epoch 77, loss: 0.06946850568056107\n",
      "Epoch 78, loss: 0.06802981346845627\n",
      "Epoch 79, loss: 0.0666513592004776\n",
      "Epoch 80, loss: 0.06532342731952667\n",
      "Epoch 81, loss: 0.06405751407146454\n",
      "Epoch 82, loss: 0.06283824890851974\n",
      "Epoch 83, loss: 0.06166728585958481\n",
      "Epoch 84, loss: 0.060532186180353165\n",
      "Epoch 85, loss: 0.05943552404642105\n",
      "Epoch 86, loss: 0.05838071554899216\n",
      "Epoch 87, loss: 0.057362478226423264\n",
      "Epoch 88, loss: 0.05639072507619858\n",
      "Epoch 89, loss: 0.05544693395495415\n",
      "Epoch 90, loss: 0.054535239934921265\n",
      "Epoch 91, loss: 0.05366092175245285\n",
      "Epoch 92, loss: 0.05281626433134079\n",
      "Epoch 93, loss: 0.051998041570186615\n",
      "Epoch 94, loss: 0.05119384452700615\n",
      "Epoch 95, loss: 0.050402142107486725\n",
      "Epoch 96, loss: 0.0496370866894722\n",
      "Epoch 97, loss: 0.048902157694101334\n",
      "Epoch 98, loss: 0.048189014196395874\n",
      "Epoch 99, loss: 0.04749729484319687\n",
      "Epoch 100, loss: 0.04682600125670433\n",
      "Epoch 101, loss: 0.046173807233572006\n",
      "Epoch 102, loss: 0.04553934186697006\n",
      "Epoch 103, loss: 0.04492298513650894\n",
      "Epoch 104, loss: 0.044323623180389404\n",
      "Epoch 105, loss: 0.04374174401164055\n",
      "Epoch 106, loss: 0.04317788407206535\n",
      "Epoch 107, loss: 0.04262721911072731\n",
      "Epoch 108, loss: 0.04208538681268692\n",
      "Epoch 109, loss: 0.04155682399868965\n",
      "Epoch 110, loss: 0.04104048013687134\n",
      "Epoch 111, loss: 0.04053811356425285\n",
      "Epoch 112, loss: 0.040042538195848465\n",
      "Epoch 113, loss: 0.03955347090959549\n",
      "Epoch 114, loss: 0.03907591477036476\n",
      "Epoch 115, loss: 0.038612209260463715\n",
      "Epoch 116, loss: 0.03815698251128197\n",
      "Epoch 117, loss: 0.037711143493652344\n",
      "Epoch 118, loss: 0.03727374225854874\n",
      "Epoch 119, loss: 0.03684762492775917\n",
      "Epoch 120, loss: 0.036431051790714264\n",
      "Epoch 121, loss: 0.03601781651377678\n",
      "Epoch 122, loss: 0.03560490533709526\n",
      "Epoch 123, loss: 0.03518267348408699\n",
      "Epoch 124, loss: 0.034779977053403854\n",
      "Epoch 125, loss: 0.034382857382297516\n",
      "Epoch 126, loss: 0.0339956060051918\n",
      "Epoch 127, loss: 0.03363221883773804\n",
      "Epoch 128, loss: 0.03327473625540733\n",
      "Epoch 129, loss: 0.032926443964242935\n",
      "Epoch 130, loss: 0.03259160369634628\n",
      "Epoch 131, loss: 0.03225994482636452\n",
      "Epoch 132, loss: 0.031936995685100555\n",
      "Epoch 133, loss: 0.03162461146712303\n",
      "Epoch 134, loss: 0.031310778111219406\n",
      "Epoch 135, loss: 0.031022848561406136\n",
      "Epoch 136, loss: 0.030727146193385124\n",
      "Epoch 137, loss: 0.030456602573394775\n",
      "Epoch 138, loss: 0.030191751196980476\n",
      "Epoch 139, loss: 0.029917540028691292\n",
      "Epoch 140, loss: 0.029667409136891365\n",
      "Epoch 141, loss: 0.029407519847154617\n",
      "Epoch 142, loss: 0.029169443994760513\n",
      "Epoch 143, loss: 0.02891978621482849\n",
      "Epoch 144, loss: 0.028693020343780518\n",
      "Epoch 145, loss: 0.028453415259718895\n",
      "Epoch 146, loss: 0.02823612093925476\n",
      "Epoch 147, loss: 0.028007909655570984\n",
      "Epoch 148, loss: 0.02780146896839142\n",
      "Epoch 149, loss: 0.027584070339798927\n",
      "Epoch 150, loss: 0.02738792821764946\n",
      "Epoch 151, loss: 0.027187976986169815\n",
      "Epoch 152, loss: 0.027000783011317253\n",
      "Epoch 153, loss: 0.026809653267264366\n",
      "Epoch 154, loss: 0.026623066514730453\n",
      "Epoch 155, loss: 0.02644079364836216\n",
      "Epoch 156, loss: 0.026262760162353516\n",
      "Epoch 157, loss: 0.026090364903211594\n",
      "Epoch 158, loss: 0.025936832651495934\n",
      "Epoch 159, loss: 0.02577104978263378\n",
      "Epoch 160, loss: 0.025608941912651062\n",
      "Epoch 161, loss: 0.025450462475419044\n",
      "Epoch 162, loss: 0.025295505300164223\n",
      "Epoch 163, loss: 0.025143934413790703\n",
      "Epoch 164, loss: 0.02499541826546192\n",
      "Epoch 165, loss: 0.02484995126724243\n",
      "Epoch 166, loss: 0.024707572534680367\n",
      "Epoch 167, loss: 0.024568216875195503\n",
      "Epoch 168, loss: 0.02443113923072815\n",
      "Epoch 169, loss: 0.024296941235661507\n",
      "Epoch 170, loss: 0.024165550246834755\n",
      "Epoch 171, loss: 0.02403668686747551\n",
      "Epoch 172, loss: 0.023909199982881546\n",
      "Epoch 173, loss: 0.023784274235367775\n",
      "Epoch 174, loss: 0.02366170845925808\n",
      "Epoch 175, loss: 0.02356819622218609\n",
      "Epoch 176, loss: 0.023461634293198586\n",
      "Epoch 177, loss: 0.02335311472415924\n",
      "Epoch 178, loss: 0.02324947901070118\n",
      "Epoch 179, loss: 0.023137276992201805\n",
      "Epoch 180, loss: 0.02303089201450348\n"
     ]
    }
   ],
   "source": [
    "train_data = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# train model\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0)\n",
    "\n",
    "epochs = 180\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for x, y in train_loader:\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, loss: {loss.item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([398, 30])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.9798994974874372\n"
     ]
    }
   ],
   "source": [
    "# test accuracy of training data\n",
    "y_pred = model(X_train_tensor)\n",
    "y_pred = y_pred.detach().numpy()\n",
    "y_pred = y_pred > 0.5\n",
    "y_pred = y_pred.astype(int)\n",
    "y_pred = y_pred.flatten()\n",
    "accuracy = np.mean(y_pred == Y_train)\n",
    "print(\"Training accuracy: \", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.9912280701754386\n"
     ]
    }
   ],
   "source": [
    "# test accuracy of test data\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "Y_test_tensor = torch.tensor(Y_test, dtype=torch.float32)\n",
    "Y_test_tensor = Y_test_tensor.view(-1, 1)\n",
    "\n",
    "y_pred = model(X_test_tensor)\n",
    "y_pred = y_pred.detach().numpy()\n",
    "y_pred = y_pred > 0.5\n",
    "y_pred = y_pred.astype(int)\n",
    "y_pred = y_pred.flatten()\n",
    "accuracy = np.mean(y_pred == Y_test)\n",
    "print(\"Test accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:  0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "# test accuracy of validation data\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "Y_val_tensor = torch.tensor(Y_val, dtype=torch.float32)\n",
    "Y_val_tensor = Y_val_tensor.view(-1, 1)\n",
    "\n",
    "y_pred = model(X_val_tensor)\n",
    "y_pred = y_pred.detach().numpy()\n",
    "y_pred = y_pred > 0.5\n",
    "y_pred = y_pred.astype(int)\n",
    "y_pred = y_pred.flatten()\n",
    "accuracy = np.mean(y_pred == Y_val)\n",
    "print(\"Validation accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with self implemented NN\n",
    "my_model = NN()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension:  30\n",
      "Epoch 0 loss:  0.6912476336503985\n",
      "Epoch 1 loss:  0.689464560678536\n",
      "Epoch 2 loss:  0.6877914014619478\n",
      "Epoch 3 loss:  0.6862210387499054\n",
      "Epoch 4 loss:  0.6847469415201028\n",
      "Epoch 5 loss:  0.6833630804244377\n",
      "Epoch 6 loss:  0.682063835303898\n",
      "Epoch 7 loss:  0.6808439038669659\n",
      "Epoch 8 loss:  0.6796982851418807\n",
      "Epoch 9 loss:  0.6786223302425334\n",
      "Epoch 10 loss:  0.6776116942279946\n",
      "Epoch 11 loss:  0.6766623044666848\n",
      "Epoch 12 loss:  0.6757703661199095\n",
      "Epoch 13 loss:  0.674932260868304\n",
      "Epoch 14 loss:  0.6741446021549439\n",
      "Epoch 15 loss:  0.673404285190266\n",
      "Epoch 16 loss:  0.6727083469456397\n",
      "Epoch 17 loss:  0.6720540351825897\n",
      "Epoch 18 loss:  0.6714387734291489\n",
      "Epoch 19 loss:  0.6708601306357853\n",
      "Epoch 20 loss:  0.6703158294013936\n",
      "Epoch 21 loss:  0.6698037360415986\n",
      "Epoch 22 loss:  0.6693218677981453\n",
      "Epoch 23 loss:  0.6688683558744392\n",
      "Epoch 24 loss:  0.6684414410119454\n",
      "Epoch 25 loss:  0.6680394585539063\n",
      "Epoch 26 loss:  0.6676608768632822\n",
      "Epoch 27 loss:  0.6673042401789658\n",
      "Epoch 28 loss:  0.6669681819828036\n",
      "Epoch 29 loss:  0.666651437686759\n",
      "Epoch 30 loss:  0.6663527842302435\n",
      "Epoch 31 loss:  0.6660710822591525\n",
      "Epoch 32 loss:  0.6658052123268227\n",
      "Epoch 33 loss:  0.6655541983419507\n",
      "Epoch 34 loss:  0.6653170252806612\n",
      "Epoch 35 loss:  0.6650928024492572\n",
      "Epoch 36 loss:  0.6648807843014445\n",
      "Epoch 37 loss:  0.6646802817588042\n",
      "Epoch 38 loss:  0.6644905321902296\n",
      "Epoch 39 loss:  0.6643108432001071\n",
      "Epoch 40 loss:  0.6641405779244052\n",
      "Epoch 41 loss:  0.6639791254535613\n",
      "Epoch 42 loss:  0.6638258965238563\n",
      "Epoch 43 loss:  0.6636803256808201\n",
      "Epoch 44 loss:  0.6635418686350342\n",
      "Epoch 45 loss:  0.663410023963617\n",
      "Epoch 46 loss:  0.6632843117489579\n",
      "Epoch 47 loss:  0.6631642532794415\n",
      "Epoch 48 loss:  0.6630493787427457\n",
      "Epoch 49 loss:  0.6629392425630367\n",
      "Epoch 50 loss:  0.6628334009136655\n",
      "Epoch 51 loss:  0.6627314222172401\n",
      "Epoch 52 loss:  0.6626328649628664\n",
      "Epoch 53 loss:  0.6625372992526443\n",
      "Epoch 54 loss:  0.6624442979402135\n",
      "Epoch 55 loss:  0.6623533853812492\n",
      "Epoch 56 loss:  0.6622641012523649\n",
      "Epoch 57 loss:  0.6621759772850452\n",
      "Epoch 58 loss:  0.6620884707235731\n",
      "Epoch 59 loss:  0.6620009963182781\n",
      "Epoch 60 loss:  0.661912959877002\n",
      "Epoch 61 loss:  0.6618236727070014\n",
      "Epoch 62 loss:  0.6617323805606442\n",
      "Epoch 63 loss:  0.6616381993550288\n",
      "Epoch 64 loss:  0.6615401567227486\n",
      "Epoch 65 loss:  0.6614370838980217\n",
      "Epoch 66 loss:  0.6613276336849238\n",
      "Epoch 67 loss:  0.6612102134694807\n",
      "Epoch 68 loss:  0.6610828503472256\n",
      "Epoch 69 loss:  0.6609432437479126\n",
      "Epoch 70 loss:  0.6607885488415588\n",
      "Epoch 71 loss:  0.6606152403477896\n",
      "Epoch 72 loss:  0.6604189495628219\n",
      "Epoch 73 loss:  0.6601942041377212\n",
      "Epoch 74 loss:  0.659934041829236\n",
      "Epoch 75 loss:  0.659629480119354\n",
      "Epoch 76 loss:  0.659268918126038\n",
      "Epoch 77 loss:  0.6588371220287563\n",
      "Epoch 78 loss:  0.6583137089561881\n",
      "Epoch 79 loss:  0.6576712985795269\n",
      "Epoch 80 loss:  0.6568723750038711\n",
      "Epoch 81 loss:  0.6558648105564278\n",
      "Epoch 82 loss:  0.6545752031105986\n",
      "Epoch 83 loss:  0.6528979057204929\n",
      "Epoch 84 loss:  0.6506785785848261\n",
      "Epoch 85 loss:  0.6476888643821824\n",
      "Epoch 86 loss:  0.6435844473154776\n",
      "Epoch 87 loss:  0.6378441640105003\n",
      "Epoch 88 loss:  0.6296833340478676\n",
      "Epoch 89 loss:  0.6179611754281165\n",
      "Epoch 90 loss:  0.6011832511372501\n",
      "Epoch 91 loss:  0.5778700441176056\n",
      "Epoch 92 loss:  0.5476900195654135\n",
      "Epoch 93 loss:  0.5129476400913285\n",
      "Epoch 94 loss:  0.47832086551075986\n",
      "Epoch 95 loss:  0.4479095354251416\n",
      "Epoch 96 loss:  0.42314041100096295\n",
      "Epoch 97 loss:  0.4033434435768855\n",
      "Epoch 98 loss:  0.3872254770237836\n",
      "Epoch 99 loss:  0.37364963739177115\n",
      "Epoch 100 loss:  0.36192105449954115\n",
      "Epoch 101 loss:  0.35157219812333734\n",
      "Epoch 102 loss:  0.3422579437212888\n",
      "Epoch 103 loss:  0.33392635847697744\n",
      "Epoch 104 loss:  0.3264596116658637\n",
      "Epoch 105 loss:  0.3194752793713115\n",
      "Epoch 106 loss:  0.3128678526160096\n",
      "Epoch 107 loss:  0.3065871361988998\n",
      "Epoch 108 loss:  0.3004859478361737\n",
      "Epoch 109 loss:  0.29463595948024773\n",
      "Epoch 110 loss:  0.2890315305505833\n",
      "Epoch 111 loss:  0.2835852565172035\n",
      "Epoch 112 loss:  0.27834644890344123\n",
      "Epoch 113 loss:  0.2733013301932594\n",
      "Epoch 114 loss:  0.26845054652548156\n",
      "Epoch 115 loss:  0.2638678660792132\n",
      "Epoch 116 loss:  0.25956884577585065\n",
      "Epoch 117 loss:  0.2554391932440137\n",
      "Epoch 118 loss:  0.25146691243384456\n",
      "Epoch 119 loss:  0.24763263954248535\n",
      "Epoch 120 loss:  0.24392606116128882\n",
      "Epoch 121 loss:  0.2403421006865803\n",
      "Epoch 122 loss:  0.2368747978241202\n",
      "Epoch 123 loss:  0.23351722755113977\n",
      "Epoch 124 loss:  0.23026446758140362\n",
      "Epoch 125 loss:  0.22711180787945245\n",
      "Epoch 126 loss:  0.2240555137666644\n",
      "Epoch 127 loss:  0.22109113594963134\n",
      "Epoch 128 loss:  0.21821458877566755\n",
      "Epoch 129 loss:  0.2154223528857418\n",
      "Epoch 130 loss:  0.21271092157476512\n",
      "Epoch 131 loss:  0.21007750666248523\n",
      "Epoch 132 loss:  0.20751779880303248\n",
      "Epoch 133 loss:  0.20499519658171148\n",
      "Epoch 134 loss:  0.20254350522125472\n",
      "Epoch 135 loss:  0.20016466867586055\n",
      "Epoch 136 loss:  0.1977726784418824\n",
      "Epoch 137 loss:  0.1954505497307567\n",
      "Epoch 138 loss:  0.19318931792214697\n",
      "Epoch 139 loss:  0.19098868407238012\n",
      "Epoch 140 loss:  0.18884635541136416\n",
      "Epoch 141 loss:  0.18676260351119706\n",
      "Epoch 142 loss:  0.184740298887641\n",
      "Epoch 143 loss:  0.18277201178906344\n",
      "Epoch 144 loss:  0.18085468513561836\n",
      "Epoch 145 loss:  0.1789840780102191\n",
      "Epoch 146 loss:  0.1771646286176409\n",
      "Epoch 147 loss:  0.17538971357801897\n",
      "Epoch 148 loss:  0.173654917781312\n",
      "Epoch 149 loss:  0.17196242726097238\n",
      "Epoch 150 loss:  0.17030764330022966\n",
      "Epoch 151 loss:  0.16869011105306864\n",
      "Epoch 152 loss:  0.16710478329280057\n",
      "Epoch 153 loss:  0.16555514979115937\n",
      "Epoch 154 loss:  0.16404102415149638\n",
      "Epoch 155 loss:  0.1625585222983534\n",
      "Epoch 156 loss:  0.16110647775664516\n",
      "Epoch 157 loss:  0.1596849503085105\n",
      "Epoch 158 loss:  0.15829003558686033\n",
      "Epoch 159 loss:  0.15692591950335277\n",
      "Epoch 160 loss:  0.15559088379959868\n",
      "Epoch 161 loss:  0.154282917750094\n",
      "Epoch 162 loss:  0.15300119673493234\n",
      "Epoch 163 loss:  0.15174547642078748\n",
      "Epoch 164 loss:  0.15051373663008993\n",
      "Epoch 165 loss:  0.14930397837693263\n",
      "Epoch 166 loss:  0.14812249115541792\n",
      "Epoch 167 loss:  0.14696275206908885\n",
      "Epoch 168 loss:  0.14582415790758657\n",
      "Epoch 169 loss:  0.14471077254205228\n",
      "Epoch 170 loss:  0.14361690812133923\n",
      "Epoch 171 loss:  0.14254430816017022\n",
      "Epoch 172 loss:  0.14149232542399937\n",
      "Epoch 173 loss:  0.1404593973311105\n",
      "Epoch 174 loss:  0.13944738149036992\n",
      "Epoch 175 loss:  0.13845456516837717\n",
      "Epoch 176 loss:  0.13747933539692844\n",
      "Epoch 177 loss:  0.1365216455329328\n",
      "Epoch 178 loss:  0.1355826110622276\n",
      "Epoch 179 loss:  0.13465931955392385\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "print(\"Input dimension: \", input_dim)\n",
    "output_dim = 1\n",
    "hidden_dims = [10, 5, 1]\n",
    "arch = [[input_dim, hidden_dims[0], 'relu'], [hidden_dims[0], hidden_dims[1], 'relu'], [hidden_dims[1], output_dim, 'sigmoid']]\n",
    "my_model = NN()\n",
    "my_model.get_input(X_train.T) \n",
    "# make sure Y_train is 2D\n",
    "Y_train_2d = Y_train.reshape(-1, 1)\n",
    "my_model.get_output(Y_train_2d.T)\n",
    "\n",
    "my_model.get_nn_architecture(arch)\n",
    "\n",
    "my_model.train(epochs=180, lr=0.01, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9798994974874372\n"
     ]
    }
   ],
   "source": [
    "# test on validation set\n",
    "y_pred = my_model.predict()\n",
    "y_pred = y_pred > 0.5\n",
    "print(\"Accuracy: \", np.mean(y_pred == Y_train_2d.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (test set):  0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "# test on test set\n",
    "my_model.get_input(X_test.T)\n",
    "my_model.get_output(Y_test.reshape(-1, 1).T)\n",
    "y_pred = my_model.predict()\n",
    "y_pred = y_pred > 0.5\n",
    "print(\"Accuracy (test set): \", np.mean(y_pred == Y_test.reshape(-1, 1).T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (validation set):  1.0\n"
     ]
    }
   ],
   "source": [
    "my_model.get_input(X_val.T)\n",
    "my_model.get_output(Y_val.reshape(-1, 1).T)\n",
    "y_pred = my_model.predict()\n",
    "y_pred = y_pred > 0.5\n",
    "print(\"Accuracy (validation set): \", np.mean(y_pred == Y_val.reshape(-1, 1).T))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
